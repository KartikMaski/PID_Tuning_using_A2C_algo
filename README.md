# Adaptive PID Tuning for Quadcopters Using Advantage Actor-Critic (A2C)

This repository is a refined and research-driven implementation of adaptive PID tuning using the **Advantage Actor-Critic (A2C)** reinforcement learning algorithm, designed for **quadcopter control in dynamic environments**.

> ğŸ”— Reference Implementation:  
> [KartikMaski/PID_Tuning_using_A2C_algo](https://github.com/KartikMaski/PID_Tuning_using_A2C_algo)

---

## ğŸ“„ Abstract

Quadcopters operate in dynamic and uncertain environments where stable control is challenging. This project presents an **A2C-based adaptive PID tuning** method that optimizes the gains in real-time based on environmental feedback, eliminating the need for static or manually-tuned PID controllers.

Our hybrid architecture combines **deep reinforcement learning (DRL)** and traditional PID mechanisms to enable robust flight control, validated through diverse simulations with disturbances and noise.

---

## ğŸ§  Key Highlights

- ğŸ” Real-time PID tuning using Advantage Actor-Critic (A2C)
- âš–ï¸ Handles variable payloads and environmental disturbances
- ğŸ§  Combines traditional control theory with modern DRL techniques
- ğŸ¯ Supports complex trajectories: Stationary, Circular, and Square

---

## ğŸ› ï¸ Tech Stack

- `Python` | `NumPy` | `Matplotlib`
- `TensorFlow` or `PyTorch` (for A2C)
- `PID Controller` logic implemented with adaptive layers

---

## ğŸ“ Architecture

The architecture features:
- **Actor-Critic Neural Network** for gain prediction and policy/value estimation
- **PID controller layer** tuned dynamically by RL agent
- **Reward shaping** based on tracking error and control effort



       [ Current State ]
              â†“
         â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”
         â”‚  Actor  â”‚â”€â”€â”€â”€â”€â–º PID Gains (Kp, Ki, Kd)
         â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
              â†“
         â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”
         â”‚  Critic â”‚â”€â”€â”€â”€â”€â–º State-Value Estimation
         â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜


## ğŸ”¬ Simulations

| Scenario            | Evaluation Description                                         |
|---------------------|----------------------------------------------------------------|
| ğŸ“ Stationary Hover | PID stabilization to fixed point with/without disturbances     |
| ğŸ”„ Circular Path    | Continuous PID adjustments for dynamic curvature path          |
| ğŸ§­ Square Path      | Abrupt turns, yaw control, and stability testing               |



## ğŸ“ˆ Results

- âœ… Effective gain tuning for altitude, pitch, roll, and yaw control  
- ğŸŒ Maintained trajectory tracking under noise and payload variation  
- ğŸ“‰ Converged to optimal policy with stable reward progression  
